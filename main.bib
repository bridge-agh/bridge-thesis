@ARTICLE{6203567,
  author={Cowling, Peter I. and Powley, Edward J. and Whitehouse, Daniel},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={Information Set Monte Carlo Tree Search}, 
  year={2012},
  volume={4},
  number={2},
  pages={120-143},
  doi={10.1109/TCIAIG.2012.2200894}}

@article{Weihua2017DesignAI,
  title={Design and implementation of bridge card game platform},
  author={Lv Weihua and Qiu Hongkun and Wang Yajie},
  journal={2017 29th Chinese Control And Decision Conference (CCDC)},
  year={2017},
  pages={7657-7660}
}

@inproceedings{Bethe2021AdvancesIC,
  title={Advances in computer bridge: techniques for a partial-information, communication-based game},
  author={Paul Bethe},
  year={2021}
}

@article{Zhang2019DesignAD,
  title={Design and Development of Bridge AI bid Program based on Double-hand Solver},
  author={Ruiyong Zhang and Hongkun Qiu and Yajie Wang and Yisheng Xiao and Jize Wang},
  journal={2019 Chinese Control And Decision Conference (CCDC)},
  year={2019},
  pages={6281-6286}
}

@article{Zhang2022TheSO,
  title={The Synergy of Double Neural Networks for Bridge Bidding},
  author={Xiaoyu Zhang and Rongheng Lin and Yuchang Bo and Fan Yang},
  journal={Mathematics},
  year={2022}
}

@article{Zhang2022AIEB,
  title={AI Enabled Bridge Bidding Supporting Interactive Visualization},
  author={Xiaoyu Zhang and Wei Liu and Linhui Lou and Fan Yang},
  journal={Sensors (Basel, Switzerland)},
  year={2022},
  volume={22}
}

@inproceedings{Ginsberg1999GIBST,
  title={GIB: Steps Toward an Expert-Level Bridge-Playing Program},
  author={Matthew L. Ginsberg},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={1999}
}

@article{Ginsberg2011GIBII,
  title={GIB: Imperfect Information in a Computationally Challenging Game},
  author={Matthew L. Ginsberg},
  journal={J. Artif. Intell. Res.},
  year={2011},
  volume={14},
  pages={303-358}
}

@article{
doi:10.1126/science.add4679,
author = {Julien Perolat  and Bart De Vylder  and Daniel Hennes  and Eugene Tarassov  and Florian Strub  and Vincent de Boer  and Paul Muller  and Jerome T. Connor  and Neil Burch  and Thomas Anthony  and Stephen McAleer  and Romuald Elie  and Sarah H. Cen  and Zhe Wang  and Audrunas Gruslys  and Aleksandra Malysheva  and Mina Khan  and Sherjil Ozair  and Finbarr Timbers  and Toby Pohlen  and Tom Eccles  and Mark Rowland  and Marc Lanctot  and Jean-Baptiste Lespiau  and Bilal Piot  and Shayegan Omidshafiei  and Edward Lockhart  and Laurent Sifre  and Nathalie Beauguerlange  and Remi Munos  and David Silver  and Satinder Singh  and Demis Hassabis  and Karl Tuyls },
title = {Mastering the game of Stratego with model-free multiagent reinforcement learning},
journal = {Science},
volume = {378},
number = {6623},
pages = {990-996},
year = {2022},
doi = {10.1126/science.add4679},
URL = {https://www.science.org/doi/abs/10.1126/science.add4679},
eprint = {https://www.science.org/doi/pdf/10.1126/science.add4679},
abstract = {We introduce DeepNash, an autonomous agent that plays the imperfect information game Stratego at a human expert level. Stratego is one of the few iconic board games that artificial intelligence (AI) has not yet mastered. It is a game characterized by a twin challenge: It requires long-term strategic thinking as in chess, but it also requires dealing with imperfect information as in poker. The technique underpinning DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego through self-play from scratch. DeepNash beat existing state-of-the-art AI methods in Stratego and achieved a year-to-date (2022) and all-time top-three ranking on the Gravon games platform, competing with human expert players. Stratego is a popular two-player imperfect information board game. Because of its complexity stemming from its enormous game tree, decision-making under imperfect information, and a piece deployment phase at the start, Stratego poses a challenge for artificial intelligence (AI). Previous computer programs only performed at an amateur level at best. Perolat et al. introduce a model-free multiagent reinforcement learning methodology and show that it can achieve human expert–level performance in Stratego. The present work not only adds to the growing list of games that AI systems can play as well or even better than humans but may also facilitate further applications of reinforcement learning methods in real-world, large-scale multiagent problems that are characterized by imperfect information and thus are currently unsolvable. —YS Reinforcement learning achieves human expert–level performance in the large-scale imperfect information board game Stratego.}}

@misc{funbridge,
  author = {{Funbridge}},
  howpublished = {\url{www.funbridge.com}}
}

@misc{bridgeace,
  author = {{BridgeAce}},
  howpublished = {\url{bridgeaceplus.com}}
}

@misc{neuralplay,
  author = {{NeuralPlay Bridge}},
  howpublished = {\url{www.neuralplay.com/bridge.html}}
}

@misc{bridgebase,
  author = {{Bridge Base}},
  howpublished = {\url{www.bridgebase.com}}
}

@misc{pmcts,
  author = {{Monte Carlo Tree Search}},
  howpublished = {\url{www.chessprogramming.org/Monte-Carlo_Tree_Search}}
}

@misc{React,
  author = {{Facebook}},
  title = {{React}},
  howpublished = {\url{reactjs.org}},
}

@misc{React-stack,
  author = {{Stack Overflow}},
  title = {{2022 Developer Survey}},
  howpublished = {\url{survey.stackoverflow.co/2022}}
}

@misc{StackOverflow,
  author = {{Stack Overflow}},
  howpublished = {\url{stackoverflow.com}}
}

@misc{Python,
  author = {{Python Software Foundation}},
  title = {{Python}},
  howpublished = {\url{www.python.org}},
}

@misc{FastAPI,
  author = {Sebastián Ramírez},
  title = {{FastAPI}},
  howpublished = {\url{fastapi.tiangolo.com}},
}

@misc{Tailwind,
  author = {{Tailwind Labs}},
  title = {{Tailwind CSS}},
  howpublished = {\url{tailwindcss.com}}
}


@misc{Firebase,
  author = {{Google}},
  title = {{Firebase}},
  howpublished = {\url{firebase.google.com}},
}

@misc{RPi,
  author = {{Raspberry Pi Foundation}},
  howpublished = {\url{www.raspberrypi.com}},
}

@misc{Discord,
  author = {{Discord}},
  howpublished = {\url{www.discord.com}},
}

@misc{Latex,
  author = {{LaTeX Project}},
  title = {{LaTeX}},
  howpublished = {\url{www.latex-project.org}},
}

@misc{Git,
  author = {{Git}},
  howpublished = {\url{www.git-scm.com}},
}

@misc{Github,
  author = {{Microsoft}},
  title = {{Github}},
  howpublished = {\url{www.github.com}},
}

@misc{GithubActions,
  author = {{Microsoft}},
  title = {{Github, Github Actions}},
  howpublished = {\url{www.github.com/features/actions}},
}

@misc{NextJS,
  author = {{Vercel}},
  title = {{Next.js}},
  howpublished = {\url{nextjs.org}},
}

@misc{Typescript,
  author = {{Microsoft}},
  title = {{Typescript}},
  howpublished = {\url{www.typescriptlang.org}},
}

@misc{DaisyUI,
  author = {{DaisyUI}},
  howpublished = {\url{daisyui.com}},
}

@misc{ReactThreeFiber,
  author = {{pmndrs}},
  title = {{React Three Fiber}},
  howpublished = {\url{github.com/pmndrs/react-three-fiber}},
}

@misc{ReactDrei,
  author = {{pmndrs}},
  title = {{React Drei}},
  howpublished = {\url{github.com/pmndrs/drei}},
}

@misc{Akka,
  author = {{Lightbend}},
  title = {{Akka}},
  howpublished = {\url{akka.io}},
}

@misc{SWR,
  author = {{Vercel}},
  title = {{SWR}},
  howpublished = {\url{swr.vercel.app}},
}

@misc{ThreeJS,
  author = {{Three.js}},
  howpublished = {\url{threejs.org}},
}

@misc{WebGL,
  author = {{Khronos Group}},
  title = {{WebGL}},
  howpublished = {\url{www.khronos.org/webgl}},
}

@misc{VSCode,
  author = {{Microsoft}},
  title = {{Visual Studio Code}},
  howpublished = {\url{code.visualstudio.com}},
}

@misc{JetBrains,
  author = {{JetBrains}},
  howpublished = {\url{www.jetbrains.com}},
}

@misc{PyCharm,
  author = {{JetBrains}},
  title = {{PyCharm}},
  howpublished = {\url{www.jetbrains.com/pycharm}},
}

@misc{Intellij,
  author = {{JetBrains}},
  title = {{IntelliJ IDEA}},
  howpublished = {\url{www.jetbrains.com/idea}},
}

@misc{Postman,
  title = {{Postman}},
  author = {{Postman Inc.}},
  howpublished = {\url{www.postman.com}},
}

@misc{Shortcut,
  title = {{Shortcut}},
  author = {{Shortcut Software Company}},
  howpublished = {\url{www.shortcut.com}},
}

@misc{Figma,
  title = {{Figma}},
  author = {{Figma Inc.}},
  howpublished = {\url{www.figma.com}},
}

@misc{FetchAPI,
  title = {{Fetch API}},
  howpublished = {\url{developer.mozilla.org/en-US/docs/Web/API/Fetch_API}},
}

@misc{WebSockets,
  title = {{WebSockets}},
  howpublished = {\url{developer.mozilla.org/en-US/docs/Web/API/WebSockets_API}},
}

@misc{IDEIndex,
  title = {{Top IDE Index}},
  author = {{Pierre Carbonnelle}},
  howpublished = {\url{pypl.github.io/IDE.html}},
}

@misc{GithubActions,
  title = {{Github Actions}},
  author = {{Microsoft}},
  howpublished = {\url{github.com/features/actions}},
}

@misc{Vercel,
  title = {{Vercel}},
  author = {{Vercel}},
  howpublished = {\url{vercel.com}},
}

@misc{OracleCloud,
  title = {{Oracle Cloud}},
  author = {{Oracle Corporation}},
  howpublished = {\url{www.oracle.com/cloud}},
}

@misc{Docker,
  title = {{Docker}},
  author = {{Docker Inc.}},
  howpublished = {\url{www.docker.com}},
}

@misc{Traefik,
  title = {{Traefik}},
  author = {{Traefik Labs}},
  howpublished = {\url{traefik.io}},
}

@book{simon1945lose,
  title={Why You Lose at Bridge},
  author={Simon, SJ},
  year={1945},
  publisher={Nicholson \& Watson},
}

@article{AlphaZeroPaper,
  title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and L. Sifre and Dharshan Kumaran and Thore Graepel and Timothy P. Lillicrap and Karen Simonyan and Demis Hassabis},
  journal={ArXiv},
  year={2017},
  volume={abs/1712.01815}
}

@article{LanctotEtAl2019OpenSpiel,
  title     = {{OpenSpiel}: A Framework for Reinforcement Learning in Games},
  author    = {Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and
               Vinicius Zambaldi and Satyaki Upadhyay and Julien P\'{e}rolat and
               Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and
               Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and
               Paul Muller and Timo Ewalds and Ryan Faulkner and J\'{a}nos Kram\'{a}r
               and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding
               and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and
               Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},
  year      = {2019},
  eprint    = {1908.09453},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  journal   = {CoRR},
  volume    = {abs/1908.09453},
  url       = {http://arxiv.org/abs/1908.09453},
}

@article{MuZeroPaper,
   title={Mastering Atari, Go, chess and shogi by planning with a learned model},
   volume={588},
   ISSN={1476-4687},
   url={http://dx.doi.org/10.1038/s41586-020-03051-4},
   DOI={10.1038/s41586-020-03051-4},
   number={7839},
   journal={Nature},
   publisher={Springer Science and Business Media LLC},
   author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
   year={2020},
   month=dec, pages={604–609} }

@inproceedings{EfficientZeroPaper,
  title={Mastering Atari Games with Limited Data},
  author={Weirui Ye, and Shaohuai Liu, and Thanard Kurutach, and Pieter Abbeel, and Yang Gao},
  booktitle={NeurIPS},
  year={2021}
}

@software{JAX,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@software{Haiku,
  author = {Tom Hennigan and Trevor Cai and Tamara Norman and Lena Martens and Igor Babuschkin},
  title = {{H}aiku: {S}onnet for {JAX}},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.10},
  year = {2020},
}

@inproceedings{PGX,
  title={Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement Learning},
  author={Koyamada, Sotetsu and Okano, Shinri and Nishimori, Soichiro and Murata, Yu and Habara, Keigo and Kita, Haruka and Ishii, Shin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@software{JAXEcosystem,
  title = {The {D}eep{M}ind {JAX} {E}cosystem},
  author = {DeepMind and Babuschkin, Igor and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and Dedieu, Antoine and Fantacci, Claudio and Godwin, Jonathan and Jones, Chris and Hemsley, Ross and Hennigan, Tom and Hessel, Matteo and Hou, Shaobo and Kapturowski, Steven and Keck, Thomas and Kemaev, Iurii and King, Michael and Kunesch, Markus and Martens, Lena and Merzic, Hamza and Mikulik, Vladimir and Norman, Tamara and Papamakarios, George and Quan, John and Ring, Roman and Ruiz, Francisco and Sanchez, Alvaro and Sartran, Laurent and Schneider, Rosalia and Sezener, Eren and Spencer, Stephen and Srinivasan, Srivatsan and Stanojevi\'{c}, Milo\v{s} and Stokowiec, Wojciech and Wang, Luyu and Zhou, Guangyao and Viola, Fabio},
  url = {http://github.com/deepmind},
  year = {2020},
}

@inproceedings{
GumbelAZ,
title={Policy improvement by planning with Gumbel},
author={Ivo Danihelka and Arthur Guez and Julian Schrittwieser and David Silver},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=bERaNdoegnO}
}

@misc{DDS,
  author          = {Bo Haglund},
  title           = {Search algorithms for a bridge double dummy solver},
  year            = {2010},
}

@misc{rong19,
      title={Competitive Bridge Bidding with Deep Neural Networks}, 
      author={Jiang Rong and Tao Qin and Bo An},
      year={2019},
      eprint={1903.00900},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{gong20,
title={Simple is Better: Training an End-to-end Contract Bridge Bidding Agent without Human Knowledge},
author={Qucheng Gong and Yu Jiang and Yuandong Tian},
year={2020},
url={https://openreview.net/forum?id=SklViCEFPH}
}

@misc{tian20,
      title={Joint Policy Search for Multi-agent Collaboration with Imperfect Information}, 
      author={Yuandong Tian and Qucheng Gong and Tina Jiang},
      year={2020},
      eprint={2008.06495},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lockhart20,
      title={Human-Agent Cooperation in Bridge Bidding}, 
      author={Edward Lockhart and Neil Burch and Nolan Bard and Sebastian Borgeaud and Tom Eccles and Lucas Smaira and Ray Smith},
      year={2020},
      eprint={2011.14124},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{Othello,
  title = {{Othello (Reversi)}},
  howpublished = {\url{https://en.wikipedia.org/wiki/Reversi}},
}
