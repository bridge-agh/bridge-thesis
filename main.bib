@ARTICLE{6203567,
  author={Cowling, Peter I. and Powley, Edward J. and Whitehouse, Daniel},
  journal={IEEE Transactions on Computational Intelligence and AI in Games}, 
  title={Information Set Monte Carlo Tree Search}, 
  year={2012},
  volume={4},
  number={2},
  pages={120-143},
  doi={10.1109/TCIAIG.2012.2200894}}

@article{Weihua2017DesignAI,
  title={Design and implementation of bridge card game platform},
  author={Lv Weihua and Qiu Hongkun and Wang Yajie},
  journal={2017 29th Chinese Control And Decision Conference (CCDC)},
  year={2017},
  pages={7657-7660}
}

@inproceedings{Bethe2021AdvancesIC,
  title={Advances in computer bridge: techniques for a partial-information, communication-based game},
  author={Paul Bethe},
  year={2021}
}

@article{Zhang2019DesignAD,
  title={Design and Development of Bridge AI bid Program based on Double-hand Solver},
  author={Ruiyong Zhang and Hongkun Qiu and Yajie Wang and Yisheng Xiao and Jize Wang},
  journal={2019 Chinese Control And Decision Conference (CCDC)},
  year={2019},
  pages={6281-6286}
}

@article{Zhang2022TheSO,
  title={The Synergy of Double Neural Networks for Bridge Bidding},
  author={Xiaoyu Zhang and Rongheng Lin and Yuchang Bo and Fan Yang},
  journal={Mathematics},
  year={2022}
}

@article{Zhang2022AIEB,
  title={AI Enabled Bridge Bidding Supporting Interactive Visualization},
  author={Xiaoyu Zhang and Wei Liu and Linhui Lou and Fan Yang},
  journal={Sensors (Basel, Switzerland)},
  year={2022},
  volume={22}
}

@inproceedings{Ginsberg1999GIBST,
  title={GIB: Steps Toward an Expert-Level Bridge-Playing Program},
  author={Matthew L. Ginsberg},
  booktitle={International Joint Conference on Artificial Intelligence},
  year={1999}
}

@article{Ginsberg2011GIBII,
  title={GIB: Imperfect Information in a Computationally Challenging Game},
  author={Matthew L. Ginsberg},
  journal={J. Artif. Intell. Res.},
  year={2011},
  volume={14},
  pages={303-358}
}

@article{
doi:10.1126/science.add4679,
author = {Julien Perolat  and Bart De Vylder  and Daniel Hennes  and Eugene Tarassov  and Florian Strub  and Vincent de Boer  and Paul Muller  and Jerome T. Connor  and Neil Burch  and Thomas Anthony  and Stephen McAleer  and Romuald Elie  and Sarah H. Cen  and Zhe Wang  and Audrunas Gruslys  and Aleksandra Malysheva  and Mina Khan  and Sherjil Ozair  and Finbarr Timbers  and Toby Pohlen  and Tom Eccles  and Mark Rowland  and Marc Lanctot  and Jean-Baptiste Lespiau  and Bilal Piot  and Shayegan Omidshafiei  and Edward Lockhart  and Laurent Sifre  and Nathalie Beauguerlange  and Remi Munos  and David Silver  and Satinder Singh  and Demis Hassabis  and Karl Tuyls },
title = {Mastering the game of Stratego with model-free multiagent reinforcement learning},
journal = {Science},
volume = {378},
number = {6623},
pages = {990-996},
year = {2022},
doi = {10.1126/science.add4679},
URL = {https://www.science.org/doi/abs/10.1126/science.add4679},
eprint = {https://www.science.org/doi/pdf/10.1126/science.add4679},
abstract = {We introduce DeepNash, an autonomous agent that plays the imperfect information game Stratego at a human expert level. Stratego is one of the few iconic board games that artificial intelligence (AI) has not yet mastered. It is a game characterized by a twin challenge: It requires long-term strategic thinking as in chess, but it also requires dealing with imperfect information as in poker. The technique underpinning DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego through self-play from scratch. DeepNash beat existing state-of-the-art AI methods in Stratego and achieved a year-to-date (2022) and all-time top-three ranking on the Gravon games platform, competing with human expert players. Stratego is a popular two-player imperfect information board game. Because of its complexity stemming from its enormous game tree, decision-making under imperfect information, and a piece deployment phase at the start, Stratego poses a challenge for artificial intelligence (AI). Previous computer programs only performed at an amateur level at best. Perolat et al. introduce a model-free multiagent reinforcement learning methodology and show that it can achieve human expert–level performance in Stratego. The present work not only adds to the growing list of games that AI systems can play as well or even better than humans but may also facilitate further applications of reinforcement learning methods in real-world, large-scale multiagent problems that are characterized by imperfect information and thus are currently unsolvable. —YS Reinforcement learning achieves human expert–level performance in the large-scale imperfect information board game Stratego.}}

@misc{funbridge,
  author = {{Funbridge}},
  howpublished = {\url{www.funbridge.com}}
}

@misc{bridgeace,
  author = {{BridgeAce}},
  howpublished = {\url{bridgeaceplus.com}}
}

@misc{neuralplay,
  author = {{NeuralPlay Bridge}},
  howpublished = {\url{www.neuralplay.com/bridge.html}}
}

@misc{bridgebase,
  author = {{Bridge Base}},
  howpublished = {\url{www.bridgebase.com}}
}

@misc{pmcts,
  author = {{Monte Carlo Tree Search}},
  howpublished = {\url{www.chessprogramming.org/Monte-Carlo_Tree_Search}}
}

@misc{React,
  author = {{Facebook}},
  title = {{React}},
  howpublished = {\url{reactjs.org}},
}

@misc{React-stack,
  author = {{Stack Overflow}},
  title = {{2022 Developer Survey}},
  howpublished = {\url{survey.stackoverflow.co/2022}}
}

@misc{StackOverflow,
  author = {{Stack Overflow}},
  howpublished = {\url{https://stackoverflow.com/}}
}

@misc{Python,
  author = {{Python Software Foundation}},
  title = {{Python}},
  howpublished = {\url{www.python.org}},
}

@misc{FastAPI,
  author = {Sebastián Ramírez},
  title = {{FastAPI}},
  howpublished = {\url{fastapi.tiangolo.com}},
}

@misc{Tailwind,
  author = {{Tailwind Labs}},
  title = {{Tailwind CSS}},
  howpublished = {\url{https://tailwindcss.com/}}
}


@misc{Firebase,
  author = {{Google}},
  title = {{Firebase}},
  howpublished = {\url{firebase.google.com}},
}


@misc{RPi,
  author = {{Raspberry Pi Foundation}},
  howpublished = {\url{www.raspberrypi.com}},
}

@book{simon1945lose,
  title={Why You Lose at Bridge},
  author={Simon, SJ},
  year={1945},
  publisher={Nicholson \& Watson},
}

@article{Silver2017MasteringCA,
  title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and L. Sifre and Dharshan Kumaran and Thore Graepel and Timothy P. Lillicrap and Karen Simonyan and Demis Hassabis},
  journal={ArXiv},
  year={2017},
  volume={abs/1712.01815}
}

@article{LanctotEtAl2019OpenSpiel,
  title     = {{OpenSpiel}: A Framework for Reinforcement Learning in Games},
  author    = {Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and
               Vinicius Zambaldi and Satyaki Upadhyay and Julien P\'{e}rolat and
               Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and
               Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and
               Paul Muller and Timo Ewalds and Ryan Faulkner and J\'{a}nos Kram\'{a}r
               and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding
               and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and
               Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},
  year      = {2019},
  eprint    = {1908.09453},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  journal   = {CoRR},
  volume    = {abs/1908.09453},
  url       = {http://arxiv.org/abs/1908.09453},
}
